{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Running fsdl text recognizer in Google colab with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venuraja79/fsdl-text-recognizer-project/blob/master/fsdl_text_recognizer_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2lY6lu_-mWF",
        "colab_type": "text"
      },
      "source": [
        "## **Full stack deep learning course**\n",
        "\n",
        "This notebook is to run the text recognizer project in Google provided colab instances.\n",
        "\n",
        "###**Things to note:**\n",
        "\n",
        "\n",
        "1.   Text recognizer project leverages pipenv for managing python packages & virtual environment\n",
        "2.   Colab GPU instance is packaged with Tensorflow version 1.14 and this supports CUDA 10.0. However the pipenv of fsdl code by default installs tf version 1.12. This has to be upgraded to 1.14 to support cuda 10.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvjP-d32629K",
        "colab_type": "code",
        "outputId": "4db0a122-3775-4a53-ea85-4b1f6de157e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Clone the code from github\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-project'...\n",
            "remote: Enumerating objects: 1293, done.\u001b[K\n",
            "remote: Total 1293 (delta 0), reused 0 (delta 0), pack-reused 1293\u001b[K\n",
            "Receiving objects: 100% (1293/1293), 2.63 MiB | 2.04 MiB/s, done.\n",
            "Resolving deltas: 100% (863/863), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfQb7GJdZ_-6",
        "colab_type": "code",
        "outputId": "29e83d8f-fbbf-4fe7-eb47-e41a6d4c2ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fsdl-text-recognizer-project  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GHZhwWdf4MG",
        "colab_type": "code",
        "outputId": "5487d456-70b2-4697-c0f9-81d4933f9215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOO8arDgGKrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065a291b-f6d7-4ec9-dcb7-6c8f02851592"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ9xV9js68g0",
        "colab_type": "code",
        "outputId": "e566d294-c33d-4f13-f7d9-2581b98dd1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd fsdl-text-recognizer-project\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dm5T29I7Mox",
        "colab_type": "code",
        "outputId": "30f193ad-5d9c-44de-e468-5425aea9618c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t  lab2_sln  lab4_sln  lab6_sln\tlab8_sln  Pipfile.lock\n",
            "lab1\t  lab3\t    lab5      lab7\tlab9\t  readme.md\n",
            "lab1_sln  lab3_sln  lab5_sln  lab7_sln\tlab9_sln\n",
            "lab2\t  lab4\t    lab6      lab8\tPipfile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb-3r2y97OeV",
        "colab_type": "code",
        "outputId": "9df38dae-06a6-48b3-b609-2de04dffb670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install pipenv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pipenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/b4/3ffa55f77161cff9a5220f162670f7c5eb00df52e00939e203f601b0f579/pipenv-2018.11.26-py3-none-any.whl (5.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.2MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=36.2.1 in /usr/local/lib/python3.6/dist-packages (from pipenv) (41.0.1)\n",
            "Collecting virtualenv-clone>=0.2.5 (from pipenv)\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/f8/50c2b7dbc99e05fce5e5b9d9a31f37c988c99acd4e8dedd720b7b8d4011d/virtualenv_clone-0.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pip>=9.0.1 in /usr/local/lib/python3.6/dist-packages (from pipenv) (19.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pipenv) (2019.6.16)\n",
            "Collecting virtualenv (from pipenv)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/9e/df208b2baad146fe3fbe750eacadd6e49bcf2f2c3c1117b7192a7b28aec4/virtualenv-16.7.2-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3MB 28.6MB/s \n",
            "\u001b[?25hInstalling collected packages: virtualenv-clone, virtualenv, pipenv\n",
            "Successfully installed pipenv-2018.11.26 virtualenv-16.7.2 virtualenv-clone-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW4U9tpFQ3Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2e8a040b-d8d4-40a2-c4ff-546b713b1d8c"
      },
      "source": [
        "!pipenv install --dev"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m\u001b[1mCreating a virtualenv for this project‚Ä¶\u001b[39m\u001b[22m\n",
            "Pipfile: \u001b[31m\u001b[1m/content/fsdl-text-recognizer-project/Pipfile\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mUsing\u001b[39m\u001b[22m \u001b[31m\u001b[1m/usr/local/bin/python\u001b[39m\u001b[22m \u001b[32m\u001b[22m(3.6.8)\u001b[39m\u001b[22m \u001b[39m\u001b[1mto create virtualenv‚Ä¶\u001b[39m\u001b[22m\n",
            "‚†∏\u001b[0m Creating virtual environment...\u001b[K\u001b[34m\u001b[22mAlready using interpreter /usr/bin/python3\n",
            "Using base prefix '/usr'\n",
            "New python executable in /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/bin/python3\n",
            "Also creating executable in /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n",
            "Running virtualenv with interpreter /usr/local/bin/python\n",
            "\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[32m\u001b[22m‚úî Successfully created virtual environment!\u001b[39m\u001b[22m\u001b[0m \n",
            "Virtualenv location: \u001b[32m\u001b[22m/root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (720db8)‚Ä¶\u001b[39m\u001b[22m\n",
            "  üêç   \u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m 121/121 ‚Äî \u001b[30m\u001b[22m00:02:04\u001b[39m\u001b[22m\n",
            "To activate this project's virtualenv, run \u001b[31m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
            "Alternatively, run a command inside the virtualenv with \u001b[31m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWdV1st5hAKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "d5e2e3c9-b8fc-4e52-9b41-1d59dbfb7ae2"
      },
      "source": [
        "!pipenv install tensorflow-gpu==1.14.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mtensorflow-gpu==1.14.0\u001b[39m\u001b[22m‚Ä¶\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mtensorflow-gpu\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[31m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m‚Ä¶\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h‚úî Installation Succeeded\u001b[0m \n",
            "\u001b[31m\u001b[1mPipfile.lock (cd86d5) out of date, updating to (720db8)‚Ä¶\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[31m\u001b[22m[dev-packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies‚Ä¶\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[31m\u001b[22m‚úò Locking Failed!\u001b[39m\u001b[22m\u001b[0m \n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/resolver.py\", line 69, in resolve\n",
            "[pipenv.exceptions.ResolutionFailure]:       req_dir=requirements_dir\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 726, in resolve_deps\n",
            "[pipenv.exceptions.ResolutionFailure]:       req_dir=req_dir,\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 480, in actually_resolve_deps\n",
            "[pipenv.exceptions.ResolutionFailure]:       resolved_tree = resolver.resolve()\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 395, in resolve\n",
            "[pipenv.exceptions.ResolutionFailure]:       raise ResolutionFailure(message=str(e))\n",
            "[pipenv.exceptions.ResolutionFailure]:       pipenv.exceptions.ResolutionFailure: ERROR: ERROR: Could not find a version that matches typed-ast<1.3.0,>=1.2.0,>=1.3.0\n",
            "[pipenv.exceptions.ResolutionFailure]:       Tried: 0.5, 0.5.1, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5.6, 0.6.0, 0.6.1, 0.6.2, 0.6.2, 0.6.2, 0.6.2, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0\n",
            "[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies.\n",
            "  First try clearing your dependency cache with $ pipenv lock --clear, then try the original command again.\n",
            " Alternatively, you can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation.\n",
            "  Hint: try $ pipenv lock --pre if it is a pre-release dependency.\n",
            "ERROR: ERROR: Could not find a version that matches typed-ast<1.3.0,>=1.2.0,>=1.3.0\n",
            "Tried: 0.5, 0.5.1, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5.6, 0.6.0, 0.6.1, 0.6.2, 0.6.2, 0.6.2, 0.6.2, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0\n",
            "There are incompatible versions in the resolved dependencies.\n",
            "[pipenv.exceptions.ResolutionFailure]:       req_dir=requirements_dir\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 726, in resolve_deps\n",
            "[pipenv.exceptions.ResolutionFailure]:       req_dir=req_dir,\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 480, in actually_resolve_deps\n",
            "[pipenv.exceptions.ResolutionFailure]:       resolved_tree = resolver.resolve()\n",
            "[pipenv.exceptions.ResolutionFailure]:   File \"/usr/local/lib/python3.6/dist-packages/pipenv/utils.py\", line 395, in resolve\n",
            "[pipenv.exceptions.ResolutionFailure]:       raise ResolutionFailure(message=str(e))\n",
            "[pipenv.exceptions.ResolutionFailure]:       pipenv.exceptions.ResolutionFailure: ERROR: ERROR: Could not find a version that matches typed-ast<1.3.0,>=1.2.0,>=1.3.0\n",
            "[pipenv.exceptions.ResolutionFailure]:       Tried: 0.5, 0.5.1, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5.6, 0.6.0, 0.6.1, 0.6.2, 0.6.2, 0.6.2, 0.6.2, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0\n",
            "[pipenv.exceptions.ResolutionFailure]: Warning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies.\n",
            "  First try clearing your dependency cache with $ pipenv lock --clear, then try the original command again.\n",
            " Alternatively, you can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation.\n",
            "  Hint: try $ pipenv lock --pre if it is a pre-release dependency.\n",
            "ERROR: ERROR: Could not find a version that matches typed-ast<1.3.0,>=1.2.0,>=1.3.0\n",
            "Tried: 0.5, 0.5.1, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5.6, 0.6.0, 0.6.1, 0.6.2, 0.6.2, 0.6.2, 0.6.2, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 0.6.3, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.0, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.1, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.2, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.3, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.0.4, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.0, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.1, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.1.2, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.2.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.0, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.1, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.2, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.4, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.3.5, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0, 1.4.0\n",
            "There are incompatible versions in the resolved dependencies.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6LE8Zxl7XUP",
        "colab_type": "code",
        "outputId": "9b85c2f7-60ed-4d0e-90b4-3eff25d3b84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/fsdl-text-recognizer-project/lab2_sln"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-project/lab2_sln\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcEdf-mI9yBS",
        "colab_type": "code",
        "outputId": "797275e4-08e4-4bab-e61f-ae46feca05fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9YZjLy3F8Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['LD_LIBRARY_PATH'] += \":/usr/local/cuda-10.0/lib64/\"\n",
        "os.environ['LD_LIBRARY_PATH'] += \":/usr/local/cuda/extras/CUPTI/lib64\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8QFERhQMaK7",
        "colab_type": "code",
        "outputId": "71887f7a-76db-448d-a821-e405fdeefbb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $LD_LIBRARY_PATH"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib64-nvidia:/usr/local/cuda-10.0/lib64/:/usr/local/cuda/extras/CUPTI/lib64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B1vh2K9Mgzl",
        "colab_type": "code",
        "outputId": "cdc5004c-7021-4a0d-c558-641c3542e184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "notebooks  readme.md  tasks  text_recognizer  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDAWnxBVGTgI",
        "colab_type": "code",
        "outputId": "11d84ada-b1bb-434d-f1e1-67aa6238f95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BzjnDVkkcs7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cd7b256-eebf-48cf-9f00-9f0c2c2ebf51"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":.\"\n",
        "\n",
        "!echo $PYTHONPATH"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python:.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkiZPDeU5i6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a80be41-5b5a-46ed-d01f-d23304681709"
      },
      "source": [
        "!PYTHONPATH=. pipenv run training/run_experiment.py --save '{\"dataset\": \"EmnistDataset\", \"model\": \"CharacterModel\", \"network\": \"mlp\",  \"train_args\": {\"batch_size\": 256}}'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running experiment with config {'dataset': 'EmnistDataset', 'model': 'CharacterModel', 'network': 'mlp', 'train_args': {'batch_size': 256}} on GPU 0\n",
            "Downloading raw dataset...\n",
            "709MB [00:38, 19.2MB/s]               \n",
            "Computing SHA-256...\n",
            "Unzipping EMNIST...\n",
            "Loading training data from .mat file\n",
            "Balancing classes to reduce amount of data\n",
            "Saving to HDF5 in a compressed format...\n",
            "Saving essential dataset parameters to text_recognizer/datasets...\n",
            "Cleaning up...\n",
            "EMNIST Dataset\n",
            "Num classes: 80\n",
            "Mapping: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z', 62: ' ', 63: '!', 64: '\"', 65: '#', 66: '&', 67: \"'\", 68: '(', 69: ')', 70: '*', 71: '+', 72: ',', 73: '-', 74: '.', 75: '/', 76: ':', 77: ';', 78: '?', 79: '_'}\n",
            "Input shape: [28, 28]\n",
            "\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 07:14:46.102617 139661636491136 deprecation.py:506] From /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 80)                10320     \n",
            "=================================================================\n",
            "Total params: 143,824\n",
            "Trainable params: 143,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<text_recognizer.models.character_model.CharacterModel object at 0x7f052b200668>\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 80)                10320     \n",
            "=================================================================\n",
            "Total params: 143,824\n",
            "Trainable params: 143,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2019-08-07 07:14:46.483662: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-08-07 07:14:46.522836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-07 07:14:46.612183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.612896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7472700 executing computations on platform CUDA. Devices:\n",
            "2019-08-07 07:14:46.612939: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-07 07:14:46.616262: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-07 07:14:46.616611: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7472fc0 executing computations on platform Host. Devices:\n",
            "2019-08-07 07:14:46.616652: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-07 07:14:46.616861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.617359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-07 07:14:46.620801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-07 07:14:46.628539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-07 07:14:46.632794: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-07 07:14:46.640422: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-07 07:14:46.649819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-07 07:14:46.660729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-07 07:14:46.675609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-07 07:14:46.675813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.676399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.676909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-07 07:14:46.676989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-07 07:14:46.678134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-07 07:14:46.678169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-07 07:14:46.678187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-07 07:14:46.678557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.679077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:14:46.679500: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-07 07:14:46.679592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Epoch 1/16\n",
            "2019-08-07 07:14:47.992195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "1314/1314 [==============================] - 14s 11ms/step - loss: 3.3770 - acc: 0.2108 - val_loss: 2.4034 - val_acc: 0.4074\n",
            "Epoch 2/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 1.2713 - acc: 0.6104 - val_loss: 0.8051 - val_acc: 0.7274\n",
            "Epoch 3/16\n",
            "1314/1314 [==============================] - 12s 9ms/step - loss: 0.9581 - acc: 0.6856 - val_loss: 0.7285 - val_acc: 0.7470\n",
            "Epoch 4/16\n",
            "1314/1314 [==============================] - 12s 9ms/step - loss: 0.8839 - acc: 0.7052 - val_loss: 0.6925 - val_acc: 0.7555\n",
            "Epoch 5/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.8445 - acc: 0.7155 - val_loss: 0.6678 - val_acc: 0.7623\n",
            "Epoch 6/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.8196 - acc: 0.7229 - val_loss: 0.6577 - val_acc: 0.7660\n",
            "Epoch 7/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.8050 - acc: 0.7268 - val_loss: 0.6478 - val_acc: 0.7691\n",
            "Epoch 8/16\n",
            "1314/1314 [==============================] - 11s 8ms/step - loss: 0.7952 - acc: 0.7294 - val_loss: 0.6431 - val_acc: 0.7708\n",
            "Epoch 9/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.7854 - acc: 0.7324 - val_loss: 0.6353 - val_acc: 0.7712\n",
            "Epoch 10/16\n",
            "1314/1314 [==============================] - 11s 8ms/step - loss: 0.7798 - acc: 0.7345 - val_loss: 0.6343 - val_acc: 0.7705\n",
            "Epoch 11/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.7755 - acc: 0.7357 - val_loss: 0.6308 - val_acc: 0.7722\n",
            "Epoch 12/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.7716 - acc: 0.7361 - val_loss: 0.6329 - val_acc: 0.7722\n",
            "Epoch 13/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.7678 - acc: 0.7378 - val_loss: 0.6247 - val_acc: 0.7748\n",
            "Epoch 14/16\n",
            "1314/1314 [==============================] - 11s 9ms/step - loss: 0.7658 - acc: 0.7394 - val_loss: 0.6269 - val_acc: 0.7743\n",
            "Epoch 00014: early stopping\n",
            "Training took 161.555672 s\n",
            "GPU utilization: 26.88 +- 2.09\n",
            "Test evaluation: 0.774328272598541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ7WpqLG5jDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "422764ba-6561-420e-8ca2-25f095d6a01f"
      },
      "source": [
        "!pipenv run pytest -s text_recognizer/tests/test_character_predictor.py"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.6.8, pytest-4.3.0, py-1.8.0, pluggy-0.9.0\n",
            "rootdir: /content/fsdl-text-recognizer-project/lab2_sln, inifile:\n",
            "collected 1 item                                                               \u001b[0m\n",
            "\n",
            "text_recognizer/tests/test_character_predictor.py WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 07:25:43.959457 140162675873664 deprecation.py:506] From /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 80)                10320     \n",
            "=================================================================\n",
            "Total params: 143,824\n",
            "Trainable params: 143,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2019-08-07 07:25:44.141031: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-08-07 07:25:44.147607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-07 07:25:44.152977: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-08-07 07:25:44.153051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: b05e60b62b0e\n",
            "2019-08-07 07:25:44.153075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: b05e60b62b0e\n",
            "2019-08-07 07:25:44.153210: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0\n",
            "2019-08-07 07:25:44.153313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0\n",
            "2019-08-07 07:25:44.153335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0\n",
            "2019-08-07 07:25:44.155488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-07 07:25:44.155761: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bb1880 executing computations on platform Host. Devices:\n",
            "2019-08-07 07:25:44.155799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-07 07:25:44.176632: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________ TestCharacterPredictor.test_filename _____________________\u001b[0m\n",
            "\n",
            "image_uri = '/content/fsdl-text-recognizer-project/lab2_sln/text_recognizer/tests/support/emnist/e.png'\n",
            "grayscale = True\n",
            "\n",
            "\u001b[1m    def read_image(image_uri: Union[Path, str], grayscale=False) -> np.array:\u001b[0m\n",
            "\u001b[1m        \"\"\"Read image_uri.\"\"\"\u001b[0m\n",
            "\u001b[1m        def read_image_from_filename(image_filename, imread_flag):\u001b[0m\n",
            "\u001b[1m            return cv2.imread(str(image_filename), imread_flag)\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m        def read_image_from_url(image_url, imread_flag):\u001b[0m\n",
            "\u001b[1m            url_response = urlopen(str(image_url))  # nosec\u001b[0m\n",
            "\u001b[1m            img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\u001b[0m\n",
            "\u001b[1m            return cv2.imdecode(img_array, imread_flag)\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m        imread_flag = cv2.IMREAD_GRAYSCALE if grayscale else cv2.IMREAD_COLOR\u001b[0m\n",
            "\u001b[1m        local_file = os.path.exists(image_uri)\u001b[0m\n",
            "\u001b[1m        try:\u001b[0m\n",
            "\u001b[1m            img = None\u001b[0m\n",
            "\u001b[1m            if local_file:\u001b[0m\n",
            "\u001b[1m                img = read_image_from_filename(image_uri, imread_flag)\u001b[0m\n",
            "\u001b[1m            else:\u001b[0m\n",
            "\u001b[1m                img = read_image_from_url(image_uri, imread_flag)\u001b[0m\n",
            "\u001b[1m>           assert img is not None\u001b[0m\n",
            "\u001b[1m\u001b[31mE           AssertionError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtext_recognizer/util.py\u001b[0m:32: AssertionError\n",
            "\n",
            "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
            "\n",
            "self = <test_character_predictor.TestCharacterPredictor testMethod=test_filename>\n",
            "\n",
            "\u001b[1m    def test_filename(self):\u001b[0m\n",
            "\u001b[1m        predictor = CharacterPredictor()\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m        for filename in SUPPORT_DIRNAME.glob('*.png'):\u001b[0m\n",
            "\u001b[1m>           pred, conf = predictor.predict(str(filename))\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtext_recognizer/tests/test_character_predictor.py\u001b[0m:18: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtext_recognizer/character_predictor.py\u001b[0m:19: in predict\n",
            "\u001b[1m    image = util.read_image(image_or_filename, grayscale=True)\u001b[0m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "image_uri = '/content/fsdl-text-recognizer-project/lab2_sln/text_recognizer/tests/support/emnist/e.png'\n",
            "grayscale = True\n",
            "\n",
            "\u001b[1m    def read_image(image_uri: Union[Path, str], grayscale=False) -> np.array:\u001b[0m\n",
            "\u001b[1m        \"\"\"Read image_uri.\"\"\"\u001b[0m\n",
            "\u001b[1m        def read_image_from_filename(image_filename, imread_flag):\u001b[0m\n",
            "\u001b[1m            return cv2.imread(str(image_filename), imread_flag)\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m        def read_image_from_url(image_url, imread_flag):\u001b[0m\n",
            "\u001b[1m            url_response = urlopen(str(image_url))  # nosec\u001b[0m\n",
            "\u001b[1m            img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\u001b[0m\n",
            "\u001b[1m            return cv2.imdecode(img_array, imread_flag)\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m        imread_flag = cv2.IMREAD_GRAYSCALE if grayscale else cv2.IMREAD_COLOR\u001b[0m\n",
            "\u001b[1m        local_file = os.path.exists(image_uri)\u001b[0m\n",
            "\u001b[1m        try:\u001b[0m\n",
            "\u001b[1m            img = None\u001b[0m\n",
            "\u001b[1m            if local_file:\u001b[0m\n",
            "\u001b[1m                img = read_image_from_filename(image_uri, imread_flag)\u001b[0m\n",
            "\u001b[1m            else:\u001b[0m\n",
            "\u001b[1m                img = read_image_from_url(image_uri, imread_flag)\u001b[0m\n",
            "\u001b[1m            assert img is not None\u001b[0m\n",
            "\u001b[1m        except Exception as e:\u001b[0m\n",
            "\u001b[1m>           raise ValueError(\"Could not load image at {}: {}\".format(image_uri, e))\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ValueError: Could not load image at /content/fsdl-text-recognizer-project/lab2_sln/text_recognizer/tests/support/emnist/e.png:\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtext_recognizer/util.py\u001b[0m:34: ValueError\n",
            "------------------------------ Captured log call -------------------------------\n",
            "deprecation.py             506 WARNING  From /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "\u001b[31m\u001b[1m=========================== 1 failed in 2.36 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqQZSqLmmigQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "744f5f88-85ed-44c2-b981-cbf2c0373077"
      },
      "source": [
        "cd /content/fsdl-text-recognizer-project/lab3_sln"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-project/lab3_sln\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR5_Tt-ZmimK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cceabd69-1322-4391-fb9f-35bd2c757fed"
      },
      "source": [
        "!pipenv run python training/run_experiment.py --save '{\"train_args\": {\"epochs\": 16}, \"dataset\": \"EmnistLinesDataset\", \"model\": \"LineModelCtc\", \"network\": \"line_lstm_ctc\"}'\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 07:26:02.424214 140540401874816 deprecation_wrapper.py:119] From /content/fsdl-text-recognizer-project/lab3_sln/text_recognizer/networks/line_lstm_ctc.py:4: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
            "\n",
            "Running experiment with config {'train_args': {'epochs': 16}, 'dataset': 'EmnistLinesDataset', 'model': 'LineModelCtc', 'network': 'line_lstm_ctc'} on GPU 0\n",
            "EmnistLinesDataset generating data...\n",
            "[nltk_data] Downloading package brown to /content/fsdl-text-\n",
            "[nltk_data]     recognizer-project/data/raw/nltk...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "EmnistLinesDataset generating data...\n",
            "EmnistLinesDataset loading data from HDF5...\n",
            "EMNIST Lines Dataset\n",
            "Max length: 34\n",
            "Max overlap: 0.33\n",
            "Num classes: 80\n",
            "Input shape: (28, 952)\n",
            "Train: (10000, 28, 952) (10000, 34, 80)\n",
            "Test: (1000, 28, 952) (1000, 34, 80)\n",
            "\n",
            "2019-08-07 07:26:27.519626: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-08-07 07:26:27.525049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-07 07:26:27.587001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.587669: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22e3f80 executing computations on platform CUDA. Devices:\n",
            "2019-08-07 07:26:27.587714: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-07 07:26:27.590297: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-07 07:26:27.590531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22e5800 executing computations on platform Host. Devices:\n",
            "2019-08-07 07:26:27.590571: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-07 07:26:27.590831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.591334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-07 07:26:27.591715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-07 07:26:27.593208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-07 07:26:27.594455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-07 07:26:27.594808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-07 07:26:27.596484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-07 07:26:27.597610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-07 07:26:27.601387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-07 07:26:27.601557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.602128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.602563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-07 07:26:27.602648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-07 07:26:27.603719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-07 07:26:27.603753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-07 07:26:27.603770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-07 07:26:27.604121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.604647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:27.605063: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-07 07:26:27.605129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0807 07:26:27.639702 140540401874816 deprecation.py:506] From /content/fsdl-text-recognizer-project/lab3_sln/text_recognizer/networks/misc.py:12: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            "W0807 07:26:27.645275 140540401874816 deprecation.py:506] From /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0807 07:26:28.258996 140540401874816 deprecation.py:323] From /root/.local/share/virtualenvs/fsdl-text-recognizer-project-Kk-lBAQO/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0807 07:26:28.306779 140540401874816 deprecation_wrapper.py:119] From /content/fsdl-text-recognizer-project/lab3_sln/text_recognizer/networks/ctc.py:24: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0807 07:26:28.311035 140540401874816 deprecation.py:323] From /content/fsdl-text-recognizer-project/lab3_sln/text_recognizer/networks/ctc.py:25: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0807 07:26:28.312864 140540401874816 deprecation.py:323] From /content/fsdl-text-recognizer-project/lab3_sln/text_recognizer/networks/ctc.py:30: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              [(None, 28, 952)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 28, 952, 1)   0           image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 189, 28, 12,  0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 189, 128)     412160      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)          (None, 189, 128)     132096      time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "y_true (InputLayer)             [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_output (Dense)          (None, 189, 80)      10320       cu_dnnlstm[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc_loss (Lambda)               (None, 1)            0           y_true[0][0]                     \n",
            "                                                                 softmax_output[0][0]             \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 label_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "ctc_decoded (Lambda)            (None, None)         0           softmax_output[0][0]             \n",
            "                                                                 lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 554,576\n",
            "Trainable params: 554,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "<text_recognizer.models.line_model_ctc.LineModelCtc object at 0x7fd1be012a58>\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              [(None, 28, 952)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 28, 952, 1)   0           image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 189, 28, 12,  0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 189, 128)     412160      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)          (None, 189, 128)     132096      time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "y_true (InputLayer)             [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_output (Dense)          (None, 189, 80)      10320       cu_dnnlstm[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           input_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc_loss (Lambda)               (None, 1)            0           y_true[0][0]                     \n",
            "                                                                 softmax_output[0][0]             \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 label_length[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "ctc_decoded (Lambda)            (None, None)         0           softmax_output[0][0]             \n",
            "                                                                 lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 554,576\n",
            "Trainable params: 554,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "W0807 07:26:28.345895 140540401874816 training_utils.py:1101] Output ctc_decoded missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to ctc_decoded.\n",
            "2019-08-07 07:26:28.480980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:28.485721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-07 07:26:28.485861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-07 07:26:28.485941: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-07 07:26:28.486006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-07 07:26:28.486052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-07 07:26:28.486126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-07 07:26:28.486193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-07 07:26:28.486244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-07 07:26:28.486390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:28.486991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:28.487581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-07 07:26:28.487686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-07 07:26:28.487719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-07 07:26:28.487741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-07 07:26:28.488203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:28.488807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-07 07:26:28.493639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10742 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Epoch 1/16\n",
            "2019-08-07 07:26:30.475214: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "2019-08-07 07:26:30.516460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-07 07:26:30.759942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "157/157 [==============================] - 86s 548ms/step - loss: 63.8661 - ctc_loss_loss: 63.8657 - val_loss: 52.7468 - val_ctc_loss_loss: 52.7468\n",
            "Epoch 2/16\n",
            "157/157 [==============================] - 80s 509ms/step - loss: 40.2558 - ctc_loss_loss: 40.2558 - val_loss: 30.4172 - val_ctc_loss_loss: 30.4172\n",
            "Epoch 3/16\n",
            "157/157 [==============================] - 80s 510ms/step - loss: 23.0388 - ctc_loss_loss: 23.0390 - val_loss: 15.7801 - val_ctc_loss_loss: 15.7801\n",
            "Epoch 4/16\n",
            "157/157 [==============================] - 80s 510ms/step - loss: 13.5483 - ctc_loss_loss: 13.5485 - val_loss: 9.7388 - val_ctc_loss_loss: 9.7388\n",
            "Epoch 5/16\n",
            "157/157 [==============================] - 80s 508ms/step - loss: 9.1985 - ctc_loss_loss: 9.1984 - val_loss: 7.9947 - val_ctc_loss_loss: 7.9947\n",
            "Epoch 6/16\n",
            "157/157 [==============================] - 80s 507ms/step - loss: 7.1140 - ctc_loss_loss: 7.1140 - val_loss: 5.9720 - val_ctc_loss_loss: 5.9720\n",
            "Epoch 7/16\n",
            "157/157 [==============================] - 80s 508ms/step - loss: 5.8763 - ctc_loss_loss: 5.8763 - val_loss: 5.4399 - val_ctc_loss_loss: 5.4399\n",
            "Epoch 8/16\n",
            "157/157 [==============================] - 80s 507ms/step - loss: 5.0703 - ctc_loss_loss: 5.0703 - val_loss: 4.9978 - val_ctc_loss_loss: 4.9978\n",
            "Epoch 9/16\n",
            "157/157 [==============================] - 80s 507ms/step - loss: 4.5560 - ctc_loss_loss: 4.5559 - val_loss: 4.5157 - val_ctc_loss_loss: 4.5157\n",
            "Epoch 10/16\n",
            "157/157 [==============================] - 79s 506ms/step - loss: 4.1632 - ctc_loss_loss: 4.1632 - val_loss: 4.1796 - val_ctc_loss_loss: 4.1796\n",
            "Epoch 11/16\n",
            "157/157 [==============================] - 80s 508ms/step - loss: 3.8258 - ctc_loss_loss: 3.8257 - val_loss: 4.0713 - val_ctc_loss_loss: 4.0713\n",
            "Epoch 12/16\n",
            "157/157 [==============================] - 79s 504ms/step - loss: 3.5625 - ctc_loss_loss: 3.5625 - val_loss: 3.8708 - val_ctc_loss_loss: 3.8708\n",
            "Epoch 13/16\n",
            "157/157 [==============================] - 79s 504ms/step - loss: 3.3613 - ctc_loss_loss: 3.3614 - val_loss: 3.8623 - val_ctc_loss_loss: 3.8623\n",
            "Epoch 14/16\n",
            "157/157 [==============================] - 80s 507ms/step - loss: 3.1702 - ctc_loss_loss: 3.1702 - val_loss: 3.6845 - val_ctc_loss_loss: 3.6845\n",
            "Epoch 15/16\n",
            "157/157 [==============================] - 79s 502ms/step - loss: 3.0100 - ctc_loss_loss: 3.0100 - val_loss: 3.5869 - val_ctc_loss_loss: 3.5869\n",
            "Epoch 16/16\n",
            "157/157 [==============================] - 79s 504ms/step - loss: 2.8635 - ctc_loss_loss: 2.8635 - val_loss: 3.5567 - val_ctc_loss_loss: 3.5567\n",
            "Training took 1280.903553 s\n",
            "GPU utilization: 84.05 +- 18.03\n",
            "\n",
            "Least accurate predictions:\n",
            "True: I\n",
            "Pred: i\n",
            "True: 104\n",
            "Pred: loy\n",
            "True: God\n",
            "Pred: aoe\n",
            "True: Mr\n",
            "Pred: mr\n",
            "True: home\n",
            "Pred: heae\n",
            "\n",
            "Most accurate predictions:\n",
            "True: manner\n",
            "Pred: manner\n",
            "True: elegantly worded\n",
            "Pred: elegantly worded\n",
            "True: their origin at\n",
            "Pred: their origin at\n",
            "True: there was a knock on it and\n",
            "Pred: there was a knock on it and\n",
            "True: out of a handy tree and first set\n",
            "Pred: out of a handy tree and first set\n",
            "\n",
            "Random predictions:\n",
            "True: If Depew had told\n",
            "Pred: if oepew had told\n",
            "True: business in bigticket\n",
            "Pred: besiness n bigticket\n",
            "True: difficult to say what\n",
            "Pred: difficult to say what\n",
            "True: for him saying But Mr\n",
            "Pred: for hin saying But mr\n",
            "True: circle By now\n",
            "Pred: circee By now\n",
            "Test evaluation: 0.9386985186516327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvwRTrBp8xw",
        "colab_type": "code",
        "outputId": "7e1fad79-3817-4f44-9cae-4dd06b82019c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!uname -m && cat /etc/*release"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x86_64\n",
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.2 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.2 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.2 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjlwxv2esfxP",
        "colab_type": "code",
        "outputId": "5fbd500b-5a7d-4e8e-abf2-c9c6b399dad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug  7 07:25:56 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    71W / 149W |     71MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Sq-QWZBVD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}